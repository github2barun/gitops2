#Logstash configuration
input {
    ######### Uncomment this pipeline address if we use FileBeat and not Logstash directly.
      #pipeline { address => pendingTransactionsDataLakePipeline }

    ######### comment out below section if we don't use logstash directly but through Filebeat.
  file {
    start_position => "beginning"
    path => ["/var/seamless/log/txe/txe-data.dump*"]
    sincedb_path => "/var/seamless/log/sincedb_data_lake_pending_transactions.log"
  }
}

#Filter out the logs before inserting to data lake
filter  {
    json{
        skip_on_invalid_json => true
        source => "message"
    }

    mutate {
      convert => { "rootComponent" => "boolean" }
        convert => { "transactionAmount" => "float" }

    }
    if ([transactionProfile] not in ["RESELLER_LINK_SUB_RESELLER","REVERSE_CREDIT_TRANSFER","CREDIT_TRANSFER","TOPUP","REVERSE_TOPUP"]) {
        drop{}
    }

    date {
      match => ["timestamp","yyyy-MM-dd HH:mm:ss","yyyy-MM-dd'T'HH:mm:ss.SSSZ"]
      timezone => "UTC"
      target => "timestamp"
    }

    ruby {
        code => "
            require 'date'
            week_n = event.get('timestamp').time.strftime '%V'
            month_n = event.get('timestamp').time.strftime '%m'
            year_n = event.get('timestamp').time.strftime '%Y'
            if(week_n == '01' && month_n == '12')
                    year_n = (year_n.to_i + 1)
                    week_num = year_n.to_s + 'w' + week_n.to_s
                else if (month_n == '01' && week_n.to_i > 50)
                    year_n = (year_n.to_i - 1)
                    week_num = year_n.to_s + 'w' + week_n.to_s
                else
                    week_num = year_n + 'w' + week_n
                end
            end
            event.set('[@metadata][week_num]', week_num)
            month_n = month_n.to_i
            event.set('[@metadata][month_num]', month_n)

            "
    }

}

output {
  stdout{
    codec => rubydebug
  }
  if ([transactionStatus] == "Pending"){
      elasticsearch {
        action => "create"
        hosts => [ "localhost:9200" ]
        index => "pending_transactions"
        document_id => "%{transactionNumber}"
        doc_as_upsert => true
      }
      elasticsearch {
        action => "create"
        hosts => [ "localhost:9200" ]
        index => "data_lake_%{[@metadata][week_num]}"
        document_id => "%{transactionNumber}"
        doc_as_upsert => true
      }
  }
  else if (([transactionStatus] == "Success" or [transactionStatus] == "Failed") and [referredErsReference] and [referredErsReference] != "") {

      elasticsearch {
              action => "create"
              hosts => [ "localhost:9200" ]
              index => "data_lake_%{[@metadata][week_num]}"
              document_id => "%{transactionNumber}"
              doc_as_upsert => true
      }
      if ([transactionStatus] == "Failed" and [resultCode] =="3"){
        elasticsearch {
                action => "delete"
                hosts => [ "localhost:9200" ]
                index => "pending_transactions"
                document_id => "%{referredErsReference}"
        }
      }
      else if ([transactionStatus] == "Success"){
        elasticsearch {
                action => "delete"
                hosts => [ "localhost:9200" ]
                index => "pending_transactions"
                document_id => "%{referredErsReference}"
        }
      }
    }
   else{
      elasticsearch {
              action => "create"
              hosts => [ "localhost:9200" ]
              index => "data_lake_%{[@metadata][week_num]}"
              document_id => "%{transactionNumber}"
              doc_as_upsert => true
      }
    }
  }