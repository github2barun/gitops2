#--------------------------------------------------------------------------------------
# Batch Scheduling Application
#-------------------------------------------------------------------------------------
spring.application.name=batch-scheduling
server.port=8085
server.servlet.context-path=/bss
#This parameter specifies the maximum size permitted for uploaded files. The default is 1MB.
spring.servlet.multipart.max-file-size=1024KB
#This parameter specifies the maximum size allowed for multipart/form-data requests. The default is 10MB.
spring.servlet.multipart.max-request-size=1228KB

# Swagger UI URL http://localhost:8085/bss/swagger-ui/index.html
# http://localhost:8085/bss/v2/api-docs
 # http://localhost:8085/bss/v3/api-docs

springdoc.swagger-ui.disable-swagger-default-url=true
messages.source.files.path=/opt/seamless/conf/batch-scheduling
logging.config=/opt/seamless/conf/batch-scheduling/log4j2.xml
## Workaround for SB-2.6.x and SpringFox which assumes that the path matching strategy of Spring MVCant-path-matcher. However the default matching strategy of Spring Boot 2.6.x is path-pattern-matcher
spring.mvc.pathmatch.matching-strategy=ant-path-matcher

#-------------------------------------------------------------------------------------
# ElastiSearch  properties
#-------------------------------------------------------------------------------------
bss.elasticsearch.userName=elastic
bss.elasticsearch.password=seamless
bss.elasticsearch.1.url=localhost
bss.elasticsearch.1.port=9200
#bss.elasticsearch.2.url=localhost
#bss.elasticsearch.2.port=9200

#when java api is enabled, the hlrc will be disabled
#bss.elasticsearch.java-api.enabled=true

#api compatibility apply only to hlrc
#can be set true only when elastic server is at least version 7.11 and shall be true when version is 8.x
#bss.elasticsearch.apiCompatibilityMode=true
#-------------------------------------------------------------------------------------
# Database connection properties
#-------------------------------------------------------------------------------------
spring.datasource.url=jdbc:mariadb://localhost:3306/batchschedulingsystem
spring.datasource.username=refill
spring.datasource.password=refill
#-------------------------------------------------------------------------------------
# JPA properties
#-------------------------------------------------------------------------------------
spring.jpa.database-platform=org.hibernate.dialect.MariaDBDialect
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.jdbc.time_zone=UTC

#-------------------------------------------------------------------------------------
# Thymeleaf configuration
#-------------------------------------------------------------------------------------
spring.thymeleaf.check-template-location=true
spring.thymeleaf.prefix=file:/opt/seamless/conf/batch-scheduling/notifications/
spring.thymeleaf.suffix=.txt
spring.thymeleaf.mode=TEXT
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.content-type=text/plain
spring.thymeleaf.cache=false

#-------------------------------------------------------------------------------------
# CORS config
#-------------------------------------------------------------------------------------
cors.enable=false
#comma separated origin list
cors.allowedorigins=http://localhost:9090,http://localhost:9091
#-------------------------------------------------------------------------------------
# Localization config
#-------------------------------------------------------------------------------------
bss.supported.languages=en,ar,fr
locale.language=en
locale.userLangPreferenceEnabled=false
locale.languageHeaderName=language


#-------------------------------------------------------------------------------------
# Batch properties
#-------------------------------------------------------------------------------------
### clientId will be helpfull to distinguish the client
### for which ftl should be used and below config will
### be used in bss.freemarker.file.path
#bss.freemarker.clientId=tt
bss.freemarker.file.path=/opt/seamless/conf/batch-scheduling/templates
###/${bss.freemarker.clientId}

bss.tmp.file.path=/var/tmp

### turn this property to true to merge error and retry file
bss.retry.file.merge=false

#-------------------------------------------------------------------------------------
# Pending Jobs DB Scanner properties
#-------------------------------------------------------------------------------------
# Frequency to scan database for jobs that are pending to be scheduled
bss.pendingJobScanner.frequency.milliseconds=120000
# Execute jobs having scheduled date older than <olderThan> seconds
bss.pendingJobScanner.olderThan.milliseconds=60000
# Limit the number of jobs to run each time the scanner runs
bss.pendingJobScanner.nbjobs.limit=10
# Limit the number of jobs to run in parallel
bss.pendingJobScanner.concurrentJobs.limit=5
# Duration (in minutes) before considering a running batch as stuck.
# Some components do not support two simultaneous executions of batches (e.g. contract).
# To not have some batches locked and waiting forever the end of the execution of a previous batch
# then a batch that has the 'processing' status and that don't update the database for some time
# will be considered as dead
bss.pendingJobScanner.processing.inactivity.timeout=30

#-------------------------------------------------------------------------------------
# OSM service connection (Object Store Manager)
#-------------------------------------------------------------------------------------
bss.osmApi.url=http://localhost:3000/osm
bss.osmApi.uri=/v1/resource/
bss.osmApi.connectionTimeout=5000
bss.osmApi.requestTimeout=60000
#-------------------------------------------------------------------------------------
# Inventory Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.imsApi.url=http://localhost/api/ims
bss.imsApi.connectionTimeout=5000
bss.imsApi.requestTimeout=60000
bss.imsApi.importInventoryUri=/v1/bulk-import
bss.imsApi.updateInventoryUri=/v1/inventory/update/bulk-import
#-------------------------------------------------------------------------------------
# Dealer Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.dmsApi.url=http://localhost/api/dms
bss.dmsApiV2.url=http://localhost/api/dms
bss.dmsApi.connectionTimeout=5000
bss.dmsApi.requestTimeout=60000
bss.dmsApi.socketTimeout=60000
bss.dmsApi.importResellerUri=/v1/resellers/create
bss.dmsApi.updateResellerUri=/v2/auth/bulkUpdate
bss.dmsApi.bulkAddResellerUsersUri=/v1/resellers/bulkAddResellerUsers
bss.dmsApi.bulkUpdateResellerUsersUri=/v2/auth/bulkUpdate
bss.dmsApi.getResellerInfoUri=/auth/getResellerInfo
bss.dmsApi.changeResellerParentUri=/v2/auth/bulkChangeParent
bss.dmsApi.changeResellerStateUri=/auth/v1/resellerChangeState
bss.dmsApi.searchResellersByAttributeUri=/auth/bulkSearchResellersByAttribute
bss.dmsApi.areaDemarcationUri=/auth/areaDemarcation
#-------------------------------------------------------------------------------------
# Voucher Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.vmsApi.url=http://localhost/api/job
bss.vmsApi.connectionTimeout=5000
bss.vmsApi.requestTimeout=60000
bss.vmsApi.blockVoucherUri=/v1/batch/BLOCK
bss.vmsApi.unblockVoucherUri=/v1/batch/UNBLOCK
bss.vmsApi.extendExpiryVoucherUri=/v1/batch/EXTEND_EXPIRY
bss.vmsApi.reconcileVoucherUri=/v1/batch/RECONCILE
bss.vmsApi.distributeVoucherUri=/v1/batch/DISTRIBUTE

#-------------------------------------------------------------------------------------
# Order Management System (through nginx)
#-------------------------------------------------------------------------------------

bss.omsApi.url=http://localhost/api/oms
bss.omsApi.connectionTimeout=5000
bss.omsApi.requestTimeout=60000

bss.omsApi.formDataEnabled=false
### if bss.omsApi.omsFormDataEnabled=true then below url should be /v1/orders
### incase of bss.omsApi.formDataEnabled=false below url should be /v2/orders
#bss.omsApi.importOrderUri=/v1/orders
bss.omsApi.importOrderUri=/v2/orders

#-------------------------------------------------------------------------------------
# HTTPStatus Codes List to be used for event success or failed accordingly
#-------------------------------------------------------------------------------------
bss.list.httpSuccessCodes=200,202

#-------------------------------------------------------------------------------------
# HTTP Gateway Error Codes List for which automatic retry mechanism will be enabled based on gatewayErrorsAutomaticRetry config parameter
#-------------------------------------------------------------------------------------
bss.list.httpGatewayErrorCodes=502,504


#-------------------------------------------------------------------------------------
# RateCard Configuration (through nginx)
#-------------------------------------------------------------------------------------
bss.rateCardApi.url=http://localhost/api/els
bss.rateCardApi.uri=/v1/ratecard
bss.rateCardApi.connectionTimeout=5000
bss.rateCardApi.resquestTimeout=60000

#-------------------------------------------------------------------------------------
# Authentication Configuration (through nginx)
#-------------------------------------------------------------------------------------
bss.idmsApi.baseUrl=http://localhost
bss.idmsApi.loginUri=/login-backend
bss.idmsApi.loginChannel=SEAMLESS-UNIFIED
# TODO MKS: Need enhancements
bss.idmsApi.loginUserId=OPERATOR
bss.idmsApi.loginPassword=2023
#-------------------------------------------------------------------------------------
# TXE (through nginx)
#-------------------------------------------------------------------------------------

bss.txeApi.url=http://localhost/api/txe
bss.txeApi.importTransferUri=/v1/bulkRequestTransfer
bss.txeApi.importTransferReversalUri=/v1/bulkReversalRequest
bss.txeApi.connectionTimeout=5000
bss.txeApi.requestTimeout=60000

#-------------------------------------------------------------------------------------
# Region Management (through nginx)
#-------------------------------------------------------------------------------------

bss.rgmsApi.url=http://localhost/api/rgms
bss.rgmsApi.createRegionHierarchy=/v1/region/?allowUpdate=true
bss.rgmsApi.connectionTimeout=5000
bss.rgmsApi.requestTimeout=60000


#-------------------------------------------------------------------------------------
# SCC-Engine (through nginx)
#-------------------------------------------------------------------------------------

bss.sccApi.bulkimportParticipateTargetAudience=http://localhost/api/scc/v1/campaign/participate-target-audience
bss.sccApi.connectionTimeout=5000
bss.sccApi.requestTimeout=60000

#-------------------------------------------------------------------------------------
# Notification Manager (through nginx)
#-------------------------------------------------------------------------------------
bss.notification.management.proxy.uri=http://localhost/api/notificationmanager
rest.template.http.max.idle=50000
rest.template.http.keep.alive=30000
rest.template.http.connection.timeout=20000
rest.template.http.read.timeout=20000

bss.notification.language.default=en_US
bss.notification.sender.email=noreply@seamless.se
bss.notification.sender.sms=Seamless
# List of recipients to notify. Empty or list amongst ADMIN and SUBMITTER
bss.notification.recipients=ADMIN,SUBMITTER
# Possible values:
# BOTH: send notification by SMS and eMail
# SMS: when the recipient has an MSISDN sends the notification by SMS otherwise by eMail
# EMAIL: when the recipient has an e-mail sends the notification by eMail otherwise by SMS
bss.notification.submitter.preferred.channel=BOTH
bss.notification.admin.preferred.channel=BOTH
bss.notification.admin.msisdn=21690xxxxxx
bss.notification.admin.email=test@seamless.se


#-------------------------------------------------------------------------------------
# Unified Client - Reference Generator
#-------------------------------------------------------------------------------------
bss.ersReferenceGenerator.class_name=com.seamless.common.referencegeneration.TimestampReferenceGenerator
bss.ersReferenceGenerator.timestamp_repeat_warning_count=10
bss.ersReferenceGenerator.reference_counter_length=10
bss.ersReferenceGenerator.node_id=01

#-------------------------------------------------------------------------------------
# Batch Reseller specific properties
#-------------------------------------------------------------------------------------

# Map enabled field to status
bss.reseller.mapping.enabledToStatus={'1':'Active', '0':'Deactivated', 'default':'Deactivated'}
bss.reseller.mapping.flagToBoolean={'0':'false', '1':'true', 'default':'false'}
bss.reseller.updateSubType=Users_Unitel_Update

bss.reseller.fieldValidationRegExp={\
    'phone':'(216)?[0-9]{8}' ,\
    'username':'[A-Z0-9-_]+' \
    }
bss.reseller.defaultAllowedFor=NONE

bss.reseller.id=Generic
bss.reseller.allowedFor=${bss.reseller.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reseller.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reseller.processor.schedTime=0 0 1 * * ?
bss.reseller.processor.schedTypeDelay-sec=60
bss.reseller.processor.failOnError=false
bss.reseller.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.reseller.processor.parallelChunkNb=10
bss.reseller.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reseller.processor.retryDelay=10
bss.reseller.file.uploadDescription=Reseller ${bss.reseller.id} import file
bss.reseller.file.supportedFormats=CSV,JSON
bss.reseller.file.format=CSV
bss.reseller.file.csv.freemarkerTemplate=reseller_import.ftl
bss.reseller.file.csv.header=fullname,cin,phone,gouvernorat_id,delegation_id,code_postal_id,address,fax,matricule_fiscal,username,otp,password,enabled,motif_desactivation,email,groupe,parent_user,code_conventionnel,digitalised,allowreport,allow_webservice_sell,email_responsable,Localisation
bss.reseller.file.csv.hasHeader=true
bss.reseller.file.csv.defaultSeparator=;
bss.reseller.file.csv.fieldMapping.resellerId=COLUMN:username
bss.reseller.file.csv.fieldMapping.resellerName=COLUMN:fullname
bss.reseller.file.csv.fieldMapping.resellerMSISDN=COLUMN:phone
bss.reseller.file.csv.fieldMapping.resellerTypeId=COLUMN:groupe
bss.reseller.file.csv.fieldMapping.parentResellerId=COLUMN:parent_user
bss.reseller.file.csv.fieldMapping.status=MAP_COLUMN:enabledToStatus:enabled
bss.reseller.file.csv.fieldMapping.address_email=COLUMN:email
#bss.reseller.file.csv.fieldMapping.address_fax=COLUMN:fax
bss.reseller.file.csv.fieldMapping.address_street=COLUMN:address
#bss.reseller.file.csv.fieldMapping.address_zip=COLUMN:code_postal_id
bss.reseller.file.csv.fieldMapping.extraParam_region=COLUMN:gouvernorat_id
bss.reseller.file.csv.fieldMapping.extraParam_delegation=COLUMN:delegation_id
bss.reseller.file.csv.fieldMapping.extraParam_matricule_fiscal=COLUMN:matricule_fiscal
bss.reseller.file.csv.fieldMapping.extraParam_customer_national_identification_id=COLUMN:cin
bss.reseller.file.csv.fieldMapping.extraParam_one_time_password=COLUMN:otp
bss.reseller.file.csv.fieldMapping.extraParam_motte_de_passe=COLUMN:password
bss.reseller.file.csv.fieldMapping.extraParam_reason_for_activation=COLUMN:motif_desactivation
bss.reseller.file.csv.fieldMapping.extraParam_code_external_system=COLUMN:code_conventionnel
bss.reseller.file.csv.fieldMapping.extraParam_allow_mobile_app=COLUMN:digitalised
bss.reseller.file.csv.fieldMapping.extraParam_allow_report=COLUMN:allowreport
bss.reseller.file.csv.fieldMapping.extraParam_allow_mobile_sell=COLUMN:allow_webservice_sell
bss.reseller.file.csv.fieldMapping.extraParam_email_responsible=COLUMN:email_responsable
bss.reseller.file.csv.fieldMapping.extraParam_postal_code=COLUMN:code_postal_id
bss.reseller.file.csv.fieldMapping.extraParam_fax=COLUMN:fax
bss.reseller.file.csv.fieldMapping.extraParam_zone_localisation=COLUMN:Localisation
bss.reseller.file.csv.fieldValidationRegExp=${bss.reseller.fieldValidationRegExp}

bss.reseller.file.csv.fieldMapping.user_userId=LIST_COLUMN:user0:USERID0

#-------------------------------------------------------------------------------------
# Batch Reseller Users
#-------------------------------------------------------------------------------------
# Map enabled field to status
bss.reselleruser.mapping.enabledToStatus={'1':'Active', '0':'Deactivated', 'default':'Deactivated'}
bss.reselleruser.mapping.flagToBoolean={'0':'false', '1':'true', 'default':'false'}
bss.reselleruser.updateSubType=resellerUser_import

bss.reselleruser.fieldValidationRegExp={\
    'phone':'(216)?[0-9]{13}' ,\
    'name':'[A-Za-z0-9-_]+' \
    }
bss.reselleruser.defaultAllowedFor=NONE

bss.reselleruser.id=Generic
bss.reselleruser.allowedFor=${bss.reselleruser.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reselleruser.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reselleruser.processor.schedTime=0 0 1 * * ?
bss.reselleruser.processor.schedTypeDelay-sec=60
bss.reselleruser.processor.failOnError=false
bss.reselleruser.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.reselleruser.processor.parallelChunkNb=10
bss.reselleruser.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reselleruser.processor.retryDelay=10
bss.reselleruser.file.uploadDescription=Reseller ${bss.reselleruser.id} import file
bss.reselleruser.file.supportedFormats=CSV
bss.reselleruser.file.format=CSV
bss.reselleruser.file.csv.freemarkerTemplate=resellerUser_import.ftl
bss.reselleruser.file.csv.header=email,name,password,phone,record_id,reseller_id,role_id,user_id
bss.reselleruser.file.csv.hasHeader=true
bss.reselleruser.file.csv.defaultSeparator=;
bss.reselleruser.file.csv.fieldMapping.email=COLUMN:email
bss.reselleruser.file.csv.fieldMapping.name=COLUMN:name
bss.reselleruser.file.csv.fieldMapping.password=COLUMN:password
bss.reselleruser.file.csv.fieldMapping.phone=COLUMN:phone
bss.reselleruser.file.csv.fieldMapping.recordId=COLUMN:record_id
bss.reselleruser.file.csv.fieldMapping.resellerId=COLUMN:reseller_id
bss.reselleruser.file.csv.fieldMapping.roleId=COLUMN:role_id
bss.reselleruser.file.csv.fieldMapping.userId=COLUMN:user_id

bss.reselleruser.file.csv.fieldValidationRegExp=${bss.reselleruser.fieldValidationRegExp}


#-------------------------------------------------------------------------------------
# Batch Inventory specific properties
#-------------------------------------------------------------------------------------

# Map brand to productSKU
bss.inventory.mapping.dsaBrandToSKU={\
    'TT':'TT_SIM_DSA',\
    'CSS':'CSS_SIM_DSA',\
    'Elissa':'ESS_SIM_DSA',\
    'Tarajji':'TARAJI_SIM_DSA',\
    'default':'TT_SIM_DSA'\
    }
bss.inventory.mapping.nonDsaBrandToSKU={\
    '0001':'TT_SIM_NON_DSA',\
    '0004':'CSS_SIM_NON_DSA',\
    '0003':'ESS_SIM_NON_DSA',\
    '0002':'TARAJI_SIM_NON_DSA',\
    'default':'TT_SIM_NON_DSA'\
    }

bss.inventory.fieldValidationRegExp={\
    'MSISDN':'(216)?[0-9]{8}' \
    }

bss.inventory.defaultAllowedFor=ALL

bss.inventory.updateSubType=Activation

bss.inventory.id=Generic
bss.inventory.allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.processor.schedTime=0 0 1 * * ?
bss.inventory.processor.schedTypeDelay-sec=30
bss.inventory.processor.failOnError=true
bss.inventory.processor.chunkSize=15
# Number of chunks executed in parallel
# bss.inventory.processor.parallelChunkNb=10
bss.inventory.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.inventory.processor.retryDelay=10
bss.inventory.file.uploadDescription=Inventory ${bss.inventory.id} import file
bss.inventory.file.supportedFormats=CSV,JSON
bss.inventory.file.format=CSV
bss.inventory.file.csv.freemarkerTemplate=inventory_import.ftl
bss.inventory.file.csv.header=SIM,BRAND,CODE_BRAND
bss.inventory.file.csv.hasHeader=true
bss.inventory.file.csv.defaultSeparator=;
bss.inventory.file.csv.fieldMapping.batchId=CONSTANT:
bss.inventory.file.csv.fieldMapping.owner=SYSTEM:uploadedBy
bss.inventory.file.csv.fieldMapping.startNo=CONSTANT:
bss.inventory.file.csv.fieldMapping.endNo=CONSTANT:
bss.inventory.file.csv.fieldMapping.state=CONSTANT:Available
bss.inventory.file.csv.fieldMapping.idType=CONSTANT:SERIAL
bss.inventory.file.csv.fieldMapping.serialNo=COLUMN:SIM
bss.inventory.file.csv.fieldMapping.locationId=SYSTEM:uploadedBy
bss.inventory.file.csv.fieldMapping.productSKU=MAP_COLUMN:dsaBrandToSKU:BRAND
bss.inventory.file.csv.fieldMapping.data_brandCode=COLUMN:CODE_BRAND

#-------------------------------------------------------------------------------------
# Inventory Import: Unkitted
#-------------------------------------------------------------------------------------
#bss.inventory.type[0].id=Unkitted
#bss.inventory.type[0].allowedFor=${bss.inventory.defaultAllowedFor}
#bss.inventory.type[0].processor.schedType=approval-pending
## Scheduling time in spring cron format (when scheduling type is 'scheduled')
#bss.inventory.type[0].processor.schedTime=0 1 * * * ?
#bss.inventory.type[0].processor.schedTypeDelay-sec=30
#bss.inventory.type[0].processor.failOnError=true
#bss.inventory.type[0].processor.chunkSize=100
## Number of chunks executed in parallel
## bss.inventory.type[0].processor.parallelChunkNb=10
#bss.inventory.type[0].file.uploadDescription=Inventory ${bss.inventory.type[0].id} import file
#bss.inventory.type[0].file.supportedFormats=CSV
#bss.inventory.type[0].file.format=CSV
#bss.inventory.type[0].file.csv.freemarkerTemplate=inventory_import.ftl
#bss.inventory.type[0].file.csv.header=kit,kit sim,kit box,kit brick,kit pallet,SIM box Serial,AgentPartner,AgentPartnerWarehouse,ERP PO Number,productSKU
#bss.inventory.type[0].file.csv.hasHeader=true
#bss.inventory.type[0].file.csv.fieldValidationUnique=AgentPartner,AgentPartnerWarehouse,productSKU
#bss.inventory.type[0].file.csv.defaultSeparator=,
#bss.inventory.type[0].file.csv.fieldMapping.productSKU=COLUMN:productSKU
#bss.inventory.type[0].file.csv.fieldMapping.batchId=SYSTEM:batchId
#bss.inventory.type[0].file.csv.fieldMapping.data_sim_box=COLUMN:SIM box Serial
#bss.inventory.type[0].file.csv.fieldMapping.serialNo=COLUMN:kit sim
#bss.inventory.type[0].file.csv.fieldMapping.owner=COLUMN:AgentPartnerWarehouse


#-------------------------------------------------------------------------------------
# Inventory Import: Kitted
#-------------------------------------------------------------------------------------
#bss.inventory.type[1].id=Kitted
#bss.inventory.type[1].allowedFor=${bss.inventory.defaultAllowedFor}
#bss.inventory.type[1].processor.schedType=approval-pending
## Scheduling time in spring cron format (when scheduling type is 'scheduled')
#bss.inventory.type[1].processor.schedTime=0 1 * * * ?
#bss.inventory.type[1].processor.schedTypeDelay-sec=30
#bss.inventory.type[1].processor.failOnError=true
#bss.inventory.type[1].processor.chunkSize=100
## Number of chunks executed in parallel
## bss.inventory.type[1].processor.parallelChunkNb=10
#bss.inventory.type[1].file.uploadDescription=Inventory ${bss.inventory.type[1].id} import file
#bss.inventory.type[1].file.supportedFormats=CSV
#bss.inventory.type[1].file.format=CSV
#bss.inventory.type[1].file.csv.freemarkerTemplate=inventory_import.ftl
#bss.inventory.type[1].file.csv.header=kit,barcode,kit sim,kit box,kit brick,kit pallet,AgentPartner,AgentPartnerWarehouse,ERP PO Number,date,productSKU
#bss.inventory.type[1].file.csv.hasHeader=true
#bss.inventory.type[1].file.csv.fieldValidationUnique=AgentPartner,AgentPartnerWarehouse,productSKU
#bss.inventory.type[1].file.csv.defaultSeparator=,
#bss.inventory.type[1].file.csv.fieldMapping.productSKU=COLUMN:productSKU
#bss.inventory.type[1].file.csv.fieldMapping.batchId=SYSTEM:batchId
#bss.inventory.type[1].file.csv.fieldMapping.serialNo=COLUMN:kit sim
#bss.inventory.type[1].file.csv.fieldMapping.owner=COLUMN:AgentPartnerWarehouse
#bss.inventory.type[1].file.csv.fieldMapping.data_box=COLUMN:kit box
#bss.inventory.type[1].file.csv.fieldMapping.data_brick=COLUMN:kit brick

#-------------------------------------------------------------------------------------
# Batch Inventory Update
#-------------------------------------------------------------------------------------
bss.inventory.type[0].id=Activation
bss.inventory.type[0].allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.type[0].processor.schedType=scheduled
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.type[0].processor.schedTime=0 0 1 * * ?
bss.inventory.type[0].processor.schedTypeDelay-sec=30
bss.inventory.type[0].processor.failOnError=true
bss.inventory.type[0].processor.chunkSize=100
# Number of chunks executed in parallel
# bss.inventory.type[0].processor.parallelChunkNb=10
bss.inventory.type[0].file.uploadDescription=Inventory ${bss.inventory.type[0].id} import file
bss.inventory.type[0].file.supportedFormats=CSV
bss.inventory.type[0].file.format=CSV
bss.inventory.type[0].file.csv.freemarkerTemplate=inventory_update_sfc.ftl
bss.inventory.type[0].file.csv.header=receiver_msisdn,activation_dt,activation_status,sim_no,city,province,primary_group
bss.inventory.type[0].file.csv.hasHeader=true
bss.inventory.type[0].file.csv.defaultSeparator=,
# bss.inventory.typ0[0].file.csv.fieldMapping.productSKU=CONSTANT:LTE SIM
bss.inventory.type[0].file.csv.fieldMapping.productSKU=CONSTANT:BOGUS
bss.inventory.type[0].file.csv.fieldMapping.serials_serialNumber=COLUMN:sim_no
bss.inventory.type[0].file.csv.fieldMapping.status=COLUMN:activation_status

#-------------------------------------------------------------------------------------
# Inventory Import: Unkitted and kitted
#-------------------------------------------------------------------------------------
bss.inventory.mapping.ownerTocanonicalId={\
    'PROVANTAGE (Pty) Ltd -GP Randburg Office(PMG Warehouse)':'RWM1',\
    'default':'%|FILE_VALUE|%'\
    }

bss.inventory.type[1].id=ASN_Import
bss.inventory.type[1].allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.type[1].processor.schedType=approval-pending
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.type[1].processor.schedTime=0 0 1 * * ?
bss.inventory.type[1].processor.schedTypeDelay-sec=30
bss.inventory.type[1].processor.failOnError=true
bss.inventory.type[1].processor.fallbackOnError=true
bss.inventory.type[1].processor.chunkSize=100
# Number of chunks executed in parallel
# bss.inventory.type[1].processor.parallelChunkNb=10
bss.inventory.type[1].file.uploadDescription=Inventory ${bss.inventory.type[1].id} import file
bss.inventory.type[1].file.supportedFormats=CSV
bss.inventory.type[1].file.format=CSV
bss.inventory.type[1].file.csv.freemarkerTemplate=inventory_import_not_empty_data.ftl
bss.inventory.type[1].file.csv.header=kit,kit sim,kit box,kit brick,SIM Box Serial,AgentPartner,AgentPartnerWarehouse,ERP PO Number,productSKU
bss.inventory.type[1].file.csv.hasHeader=true
bss.inventory.type[1].file.csv.defaultSeparator=,
bss.inventory.type[1].file.csv.fieldValidationUnique=AgentPartner,AgentPartnerWarehouse
bss.inventory.type[1].file.csv.exclusiveFieldsValidation=SIM Box Serial,kit box|SIM Box Serial,kit brick
bss.inventory.type[1].file.csv.fieldMapping.productSKU=COLUMN:productSKU
bss.inventory.type[1].file.csv.fieldMapping.batchId=SYSTEM:batchId
bss.inventory.type[1].file.csv.fieldMapping.serialNo=COLUMN:kit sim
bss.inventory.type[1].file.csv.fieldMapping.owner=MAP_COLUMN:ownerTocanonicalId:AgentPartnerWarehouse
#unkitted
bss.inventory.type[1].file.csv.fieldMapping.data_sim_box=COLUMN:SIM Box Serial
#kitted
bss.inventory.type[1].file.csv.fieldMapping.data_box=COLUMN:kit box
bss.inventory.type[1].file.csv.fieldMapping.data_brick=COLUMN:kit brick




#-------------------------------------------------------------------------------------
# Batch Order specific properties
#-------------------------------------------------------------------------------------

bss.order.defaultAllowedFor=NONE

bss.order.id=Generic
bss.order.allowedFor=${bss.order.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.order.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.order.processor.schedTime=0 0 1 * * ?
bss.order.processor.schedTypeDelay-sec=60
bss.order.processor.failOnError=false
bss.order.processor.chunkSize=1
# Number of chunks executed in parallel
# bss.order.processor.parallelChunkNb=10
bss.order.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.order.processor.retryDelay=10
bss.order.file.uploadDescription=Order ${bss.order.id} import file
bss.order.file.supportedFormats=CSV,JSON
bss.order.file.format=CSV
bss.order.file.csv.freemarkerTemplate=order_import.ftl
bss.order.file.csv.header=Order_Type,Product_SKU,Buyer,Seller,Reserve_Type,Start_Serial,End_Serial,Return_Type,Return_Reason,Description
bss.order.file.csv.hasHeader=true
bss.order.file.csv.defaultSeparator=,
bss.order.file.csv.fieldMapping.buyerId=COLUMN:Buyer
bss.order.file.csv.fieldMapping.sellerId=COLUMN:Seller
bss.order.file.csv.fieldMapping.items_productSku=COLUMN:Product_SKU
bss.order.file.csv.fieldMapping.items_reserveType=COLUMN:Reserve_Type
bss.order.file.csv.fieldMapping.ranges_startSerial=COLUMN:Start_Serial
bss.order.file.csv.fieldMapping.ranges_endSerial=COLUMN:End_Serial
bss.order.file.csv.fieldMapping.orderType=COLUMN:Order_Type
bss.order.file.csv.fieldMapping.returnType=COLUMN:Return_Type
bss.order.file.csv.fieldMapping.returnReason=COLUMN:Return_Reason
bss.order.file.csv.fieldMapping.clientComment=COLUMN:Description



#-------------------------------------------------------------------------------------
# Batch Reverse Order specific properties
#-------------------------------------------------------------------------------------

bss.reverseorder.defaultAllowedFor=NONE

bss.reverseorder.id=Generic
bss.reverseorder.allowedFor=${bss.reverseorder.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reverseorder.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reverseorder.processor.schedTime=0 0 1 * * ?
bss.reverseorder.processor.schedTypeDelay-sec=60
bss.reverseorder.processor.failOnError=false
### Keep the chunkSize=1 because currently OMS only supports chunkSize=1
bss.reverseorder.processor.chunkSize=1
# Number of chunks executed in parallel
# bss.reverseorder.processor.parallelChunkNb=10
bss.reverseorder.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reverseorder.processor.retryDelay=10
bss.reverseorder.file.uploadDescription=Reverse order file
bss.reverseorder.file.supportedFormats=CSV,JSON
bss.reverseorder.file.format=CSV
bss.reverseorder.file.csv.freemarkerTemplate=order_reverse.ftl
bss.reverseorder.file.csv.header=OrderId,Description
bss.reverseorder.file.csv.hasHeader=true
bss.reverseorder.file.csv.defaultSeparator=,
bss.reverseorder.file.csv.fieldMapping.orderId=COLUMN:OrderId
bss.reverseorder.file.csv.fieldMapping.description=COLUMN:Description

#-------------------------------------------------------------------------------------
# Batch RateCard specific properties
#-------------------------------------------------------------------------------------

bss.ratecard.defaultAllowedFor=NONE
bss.ratecard.id=RateCard
bss.ratecard.allowedFor=${bss.ratecard.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.ratecard.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.ratecard.processor.schedTime=0 0 1 * * ?
bss.ratecard.processor.schedTypeDelay-sec=10
bss.ratecard.processor.failOnError=false
bss.ratecard.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.ratecard.processor.parallelChunkNb=10
bss.ratecard.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.ratecard.processor.retryDelay=10
bss.ratecard.file.uploadDescription=${bss.ratecard.id} import file
bss.ratecard.file.supportedFormats=CSV,JSON
bss.ratecard.file.format=CSV
bss.ratecard.file.csv.freemarkerTemplate=ratecard_import.ftl
bss.ratecard.file.csv.header=Pickup Location,Drop Location,Distance(Km),Minimum Capacity(KG),Maximum Capacity(KG),Rate,Logistic Type,SelfLoad,Flat Rate Capacity(KG),Additional Rate / KG,Status,Vendor,Priority Rate
bss.ratecard.file.csv.hasHeader=true
bss.ratecard.file.csv.defaultSeparator=,
bss.ratecard.file.csv.fieldMapping.vendor=COLUMN:Vendor
bss.ratecard.file.csv.fieldMapping.pickupLocation=COLUMN:Pickup Location
bss.ratecard.file.csv.fieldMapping.dropLocation=COLUMN:Drop Location
bss.ratecard.file.csv.fieldMapping.distance=COLUMN:Distance(Km)
bss.ratecard.file.csv.fieldMapping.status=COLUMN:Status
bss.ratecard.file.csv.fieldMapping.minKg=COLUMN:Minimum Capacity(KG)
bss.ratecard.file.csv.fieldMapping.maxKg=COLUMN:Maximum Capacity(KG)
bss.ratecard.file.csv.fieldMapping.charge=COLUMN:Rate
bss.ratecard.file.csv.fieldMapping.type=COLUMN:Logistic Type
bss.ratecard.file.csv.fieldMapping.flatUptoKg=COLUMN:Flat Rate Capacity(KG)
bss.ratecard.file.csv.fieldMapping.extraChargeAfterMaxKg=COLUMN:Additional Rate / KG
bss.ratecard.file.csv.fieldMapping.selfload=COLUMN:SelfLoad
bss.ratecard.file.csv.fieldMapping.priorityRate=COLUMN:Priority Rate


#-------------------------------------------------------------------------------------
# Batch CX specific properties
#-------------------------------------------------------------------------------------

bss.cx.defaultAllowedFor=NONE

bss.cx.id=Generic
bss.cx.allowedFor=${bss.cx.defaultAllowedFor}
bss.cx.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.cx.processor.schedTime=0 0 1 * * ?
bss.cx.processor.schedTypeDelay-sec=30
bss.cx.processor.failOnError=false
#for cx use case the chunkSize must always be an even number
bss.cx.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.cx.processor.parallelChunkNb=10
bss.cx.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.cx.processor.retryDelay=10
bss.cx.file.uploadDescription=CX import file
bss.cx.file.supportedFormats=CSV
bss.cx.file.format=CSV
bss.cx.file.csv.freemarkerTemplate=inventory_update.ftl
bss.cx.file.csv.header=MSISDN,SIM,date,user
bss.cx.file.csv.hasHeader=false
bss.cx.file.csv.defaultSeparator=|
bss.cx.file.csv.fieldMapping.status=CONSTANT:CX sold


#-------------------------------------------------------------------------------------
# Batch Notification specific properties
#-------------------------------------------------------------------------------------

bss.bulknotification.id=Generic
# Not Allowed in import GUI
bss.bulknotification.allowedFor=
bss.bulknotification.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.bulknotification.processor.schedTime=0 0 1 * * ?
bss.bulknotification.processor.schedTypeDelay-sec=30
bss.bulknotification.processor.failOnError=false
bss.bulknotification.processor.chunkSize=20
# Number of chunks executed in parallel
bss.bulknotification.processor.parallelChunkNb=5
bss.bulknotification.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.bulknotification.processor.retryDelay=10
bss.bulknotification.file.uploadDescription=Notification import file
bss.bulknotification.file.supportedFormats=CSV
bss.bulknotification.file.format=CSV
bss.bulknotification.file.csv.freemarkerTemplate=notification.ftl
bss.bulknotification.file.csv.header=recipient
bss.bulknotification.file.csv.hasHeader=false
bss.bulknotification.file.csv.defaultSeparator=|


#-------------------------------------------------------------------------------------
# Batch Retry Notification specific properties
#-------------------------------------------------------------------------------------

bss.retrynotification.id=Generic
# Not Allowed in import GUI
bss.retrynotification.allowedFor=
bss.retrynotification.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.retrynotification.processor.schedTime=0 0 1 * * ?
bss.retrynotification.processor.schedTypeDelay-sec=30
bss.retrynotification.processor.failOnError=false
# Only chunkSize=1 is supported
bss.retrynotification.processor.chunkSize=1
# Number of chunks executed in parallel
bss.retrynotification.processor.parallelChunkNb=10
bss.retrynotification.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.retrynotification.processor.retryDelay=10
bss.retrynotification.file.uploadDescription="Retry notification import file"
bss.retrynotification.file.supportedFormats=CSV
bss.retrynotification.file.format=CSV
bss.retrynotification.file.csv.freemarkerTemplate=retry_notification.ftl
bss.retrynotification.file.csv.header=TDR
bss.retrynotification.file.csv.hasHeader=false
bss.retrynotification.file.csv.defaultSeparator=|

#-------------------------------------------------------------------------------------
# voucher for Generic
#-------------------------------------------------------------------------------------
bss.voucher.defaultAllowedFor=ALL
#Generic import for voucher is not allowed
bss.voucher.id=Generic
bss.voucher.allowedFor=NOT_ALLOWED
bss.voucher.operation=NO_OPERATION
bss.voucher.file.supportedFormats=CSV
bss.voucher.file.format=CSV
bss.voucher.file.csv.freemarkerTemplate=voucher_import.ftl
#-------------------------------------------------------------------------------------
# Batch files by elasticsearch
#-------------------------------------------------------------------------------------
# List of the es scanners (comma separated list. can be empty)
bss.esScanners=retryNotification
# 
bss.esScanners.retryNotification.enable=false
bss.esScanners.retryNotification.batchType=RetryNotification
#bss.esScanners.retryNotification.batchSubType=
bss.esScanners.retryNotification.uploadedBy=retryES
# to avoid sending multiple notification, this esScanner for retry notitication shall be scheduled 
# at an iterval longer then the interval needed to reach the notification manager 
# cumulated with interval neeeded by it to resend and update the status in notification_data_lake_*
bss.esScanners.retryNotification.cron.schedule=0 30 * * * ?
#JSON or CSV, depend of next processing
bss.esScanners.retryNotification.line.format=JSON
#mandatory for CSV line format:
#bss.esScanners.retryNotification.line.CSV.separator=|
bss.esScanners.retryNotification.batchesPerFile=10
#batch size must not exceed 10000
bss.esScanners.retryNotification.es.batchSize=10000
bss.esScanners.retryNotification.es.query={"bool": {"must": {"term": {"notificationmanager.notificationMessage.status": "retriable"}}, "should": [{"match": {"notificationmanager.notificationMessage.notificationType": "SMS"}}, {"match": {"notificationmanager.notificationMessage.notificationType": "EMAIL"}}], "minimum_should_match" : 1}}}
bss.esScanners.retryNotification.es.index=notification_data_lake_*


#-------------------------------------------------------------------------------------
# Batch files by FTP
#-------------------------------------------------------------------------------------
# List of the FTP directory scanners (comma separated list. can be empty)
#bss.ftpFileScanners=kitted,unkitted
bss.ftpFileScanners=ASN_Import,Activation

# Kitted Inventory files
#bss.ftpFileScanner.kitted.enable=false
#bss.ftpFileScanner.kitted.batchType=Inventory
#bss.ftpFileScanner.kitted.batchSubType=Kitted
#bss.ftpFileScanner.kitted.uploadedBy=rcvdCX
#bss.ftpFileScanner.kitted.cron.schedule=0 0/2 * * * ?
#bss.ftpFileScanner.kitted.host=localhost
##For SFTP port will be 22
#bss.ftpFileScanner.kitted.port=22
##It will be either FTP or SFTP, by default it will be FTP
#bss.ftpFileScanner.kitted.protocol=SFTP
#bss.ftpFileScanner.kitted.username=centos
#bss.ftpFileScanner.kitted.password=seamless
#bss.ftpFileScanner.kitted.file.prefix=Kitted
#bss.ftpFileScanner.kitted.directory.input=/root/kitted/uploads
#bss.ftpFileScanner.kitted.directory.stage=/root/kitted/uploads/stage
#bss.ftpFileScanner.kitted.directory.failed=/root/kitted/uploads/validations-not-successful
#bss.ftpFileScanner.kitted.directory.processed=/root/kitted/uploads/processed

# Unkitted Inventory files
#bss.ftpFileScanner.unkitted.enable=false
#bss.ftpFileScanner.unkitted.batchType=Inventory
#bss.ftpFileScanner.unkitted.batchSubType=Unkitted
#bss.ftpFileScanner.unkitted.uploadedBy=rcvdCX
#bss.ftpFileScanner.unkitted.cron.schedule=0 0/2 * * * ?
#bss.ftpFileScanner.unkitted.host=localhost
##For SFTP port will be 22
#bss.ftpFileScanner.unkitted.port=22
##It will be either FTP or SFTP, by default it will be FTP
#bss.ftpFileScanner.unkitted.protocol=SFTP
#bss.ftpFileScanner.unkitted.username=centos
#bss.ftpFileScanner.unkitted.password=seamless
#bss.ftpFileScanner.unkitted.file.prefix=Unkitted
#bss.ftpFileScanner.unkitted.directory.input=/root/unkitted/uploads
#bss.ftpFileScanner.unkitted.directory.stage=/root/unkitted/uploads/stage
#bss.ftpFileScanner.unkitted.directory.failed=/root/unkitted/uploads/validations-not-successful
#bss.ftpFileScanner.unkitted.directory.processed=/root/unkitted/uploads/processed

# Inventory Import files
bss.ftpFileScanner.ASN_Import.enable=true
bss.ftpFileScanner.ASN_Import.batchType=Inventory
bss.ftpFileScanner.ASN_Import.batchSubType=ASN_Import
bss.ftpFileScanner.ASN_Import.uploadedBy=rcvdCX
bss.ftpFileScanner.ASN_Import.cron.schedule=0 0/2 * * * ?
bss.ftpFileScanner.ASN_Import.host=localhost
#For SFTP port will be 22
bss.ftpFileScanner.ASN_Import.port=22
#It will be either FTP or SFTP, by default it will be FTP
bss.ftpFileScanner.ASN_Import.protocol=SFTP
bss.ftpFileScanner.ASN_Import.username=centos
bss.ftpFileScanner.ASN_Import.password=seamless
bss.ftpFileScanner.ASN_Import.file.prefix=ASN_Import
bss.ftpFileScanner.ASN_Import.directory.input=/root/inventory/uploads
bss.ftpFileScanner.ASN_Import.directory.stage=/root/inventory/uploads/stage
bss.ftpFileScanner.ASN_Import.directory.failed=/root/inventory/uploads/validations-not-successful
bss.ftpFileScanner.ASN_Import.directory.processed=/root/inventory/uploads/processed

# Inventory Activation files
bss.ftpFileScanner.Activation.enable=true
bss.ftpFileScanner.Activation.batchType=Inventory
bss.ftpFileScanner.Activation.batchSubType=Activation
bss.ftpFileScanner.Activation.uploadedBy=rcvdCX
bss.ftpFileScanner.Activation.cron.schedule=0 0/2 * * * ?
bss.ftpFileScanner.Activation.host=localhost
#For SFTP port will be 22
bss.ftpFileScanner.Activation.port=22
#It will be either FTP or SFTP, by default it will be FTP
bss.ftpFileScanner.Activation.protocol=SFTP
bss.ftpFileScanner.Activation.username=centos
bss.ftpFileScanner.Activation.password=seamless
bss.ftpFileScanner.Activation.file.prefix=Activation
bss.ftpFileScanner.Activation.directory.input=/root/activation/uploads
bss.ftpFileScanner.Activation.directory.stage=/root/activation/uploads/stage
bss.ftpFileScanner.Activation.directory.failed=/root/activation/uploads/validations-not-successful
bss.ftpFileScanner.Activation.directory.processed=/root/activation/uploads/processed

#-------------------------------------------------------------------------------------
# Batch files by Local Directory Scanning
#-------------------------------------------------------------------------------------
# List of the Local directory scanners (comma separated list. can be empty)
bss.localFileScanners=ASN_Import,Activation

# Import Kitted Inventory files
bss.localFileScanner.ASN_Import.enable=true
bss.localFileScanner.ASN_Import.batchType=Inventory
bss.localFileScanner.ASN_Import.batchSubType=ASN_Import
bss.localFileScanner.ASN_Import.uploadedBy=rcvdImportInventory
bss.localFileScanner.ASN_Import.cron.schedule=0 0/2 * * * ?
bss.localFileScanner.ASN_Import.file.prefix=ASN_Import
bss.localFileScanner.ASN_Import.directory.input=/home/admin/batch-scheduling/inventory/uploads
bss.localFileScanner.ASN_Import.directory.stage=/home/admin/batch-scheduling/inventory/uploads/stage
bss.localFileScanner.ASN_Import.directory.failed=/home/admin/batch-scheduling/inventory/uploads/validations-not-successful
bss.localFileScanner.ASN_Import.directory.processed=/home/admin/batch-scheduling/inventory/uploads/processed

# Import Kitted Inventory files
bss.localFileScanner.Activation.enable=true
bss.localFileScanner.Activation.batchType=Inventory
bss.localFileScanner.Activation.batchSubType=Activation
bss.localFileScanner.Activation.uploadedBy=rcvdImportInventory
bss.localFileScanner.Activation.cron.schedule=0 0/2 * * * ?
bss.localFileScanner.Activation.file.prefix=Activation
bss.localFileScanner.Activation.directory.input=/home/admin/batch-scheduling/activation/uploads
bss.localFileScanner.Activation.directory.stage=/home/admin/batch-scheduling/activation/uploads/stage
bss.localFileScanner.Activation.directory.failed=/home/admin/batch-scheduling/activation/uploads/validations-not-successful
bss.localFileScanner.Activation.directory.processed=/home/admin/batch-scheduling/activation/uploads/processed


# Import Kitted Inventory files
#bss.localFileScanner.kitted.enable=true
#bss.localFileScanner.kitted.batchType=Inventory
#bss.localFileScanner.kitted.batchSubType=Kitted
#bss.localFileScanner.kitted.uploadedBy=rcvdImportInventory
#bss.localFileScanner.kitted.cron.schedule=0 0/2 * * * ?
#bss.localFileScanner.kitted.file.prefix=Kitted
#bss.localFileScanner.kitted.directory.input=/home/admin/batch-scheduling/kitted/uploads
#bss.localFileScanner.kitted.directory.stage=/home/admin/batch-scheduling/kitted/uploads/stage
#bss.localFileScanner.kitted.directory.failed=/home/admin/batch-scheduling/kitted/uploads/validations-not-successful
#bss.localFileScanner.kitted.directory.processed=/home/admin/batch-scheduling/kitted/uploads/processed

# Import Unkitted Inventory files
#bss.localFileScanner.unkitted.enable=true
#bss.localFileScanner.unkitted.batchType=Inventory
#bss.localFileScanner.unkitted.batchSubType=Unkitted
#bss.localFileScanner.unkitted.uploadedBy=rcvdImportInventory
#bss.localFileScanner.unkitted.cron.schedule=0 0/2 * * * ?
#bss.localFileScanner.unkitted.file.prefix=Unkitted
#bss.localFileScanner.unkitted.directory.input=/home/admin/batch-scheduling/unkitted/uploads
#bss.localFileScanner.unkitted.directory.stage=/home/admin/batch-scheduling/unkitted/uploads/stage
#bss.localFileScanner.unkitted.directory.failed=/home/admin/batch-scheduling/unkitted/uploads/validations-not-successful
#bss.localFileScanner.unkitted.directory.processed=/home/admin/batch-scheduling/unkitted/uploads/processed


#-------------------------------------------------------------------------------------
# Get Scheduled Batches, Get Import Info and Get Batch Info specific properties
#-------------------------------------------------------------------------------------
bss.history.visibleFor=Dealer,Sub Dealer
#bss.history.visibleFor=ALL

#-------------------------------------------------------------------------------------
# Audit feed config
#-------------------------------------------------------------------------------------
auditFeed.version=1
auditFeed.componentName=batch-scheduling
auditFeed.eventType=audit
# list of events can be either `INCLUDE` or `EXCLUDE`
audit.feed.list.type=EXCLUDE
# comma separated list
audit.feed.list.events=
auditFeed.freemarker.file.path=/opt/seamless/conf/batch-scheduling/auditfeeder/templates
auditFeed.default.template=batchscheduling_audit_feed.ftl

#-------------------------------------------------------------------------------------
# Data Feeder properties
#-------------------------------------------------------------------------------------
dataFeed.freemarker.file.path=/opt/seamless/conf/batch-scheduling/datafeeder/templates
threadpoolmanager.pools.dataFeed.targetId=com.seamless.common.data.dump.dataFeed
threadpoolmanager.pools.dataFeed.corePoolSize=25
threadpoolmanager.pools.dataFeed.maxPoolSize=40
threadpoolmanager.pools.dataFeed.keepAliveTime=60000
threadpoolmanager.pools.dataFeed.keepAliveTimeUnit=MILLISECONDS

dataFeed.version=1
#dataFeed.componentName=batchscheduling
dataFeed.componentName=bss
dataFeed.eventType=Report

#template.IMPORT_RATECARD=batchschedulingFeed_importGeneric.ftl
template.IMPORT_INVENTORY=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_RESELLER=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_RESELLER_USER=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_ORDER=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_REVERSEORDER=batchschedulingFeed_importGeneric.ftl
template.IMPORT_RESUBMIT=batchschedulingFeed_importGeneric.ftl
template.GET_IMPORT_INFO=batchschedulingFeed_importGeneric.ftl
template.GET_SERVICE_INFO=batchschedulingFeed_serviceInfo.ftl
template.GET_BATCH_INFO=batchschedulingFeed_batchInfo.ftl
template.GET_SCHEDULED_BATCHES=batchschedulingFeed_scheduledBatches.ftl
#template.IMPORT_TRANSACTION=batchschedulingFeed_importGeneric.ftl
template.UPDATE_IMPORT_TASK=batchschedulingFeed_updateImportTask.ftl
template.IMPORT_NOTIFICATION=batchschedulingFeed_importNotification.ftl
template.IMPORT_VOUCHER=batchschedulingFeed_importGeneric.ftl
template.IMPORT_DEMARCATION=batchschedulingFeed_importGeneric.ftl


#-------------------------------------------------------------------------------------
# Batch Transaction specific properties
#-------------------------------------------------------------------------------------

#requestHeader.O2C_SALE={"ref-prefix":"OT"}
#requestHeader.O2C_SALE_DIST={"ref-prefix":"OT"}
#requestHeader.O2C_SALE_RET={"ref-prefix":"OT"}
#requestHeader.O2C_FOC={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_RET={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_DIST={"ref-prefix":"OT"}
#requestHeader.TRANSACTION_REVERSAL={"ref-prefix":"BD"}
#requestHeader.C2C={"ref-prefix":"CT"}
#requestHeader.O2C_WITHDRAW={"ref-prefix":"OW"}
#requestHeader.C2C_WITHDRAW={"ref-prefix":"CW"}
#requestHeader.C2C_MULTIWALLET_SELF={"ref-prefix":"WT"}
#requestHeader.C2S_RECONCILIATION={"ref-prefix":"BD"}
#requestHeader.O2C_SALE_ESDIST={"ref-prefix":"OT"}
#requestHeader.O2C_SALE_EADIST={"ref-prefix":"OT"}
#requestHeader.O2C_SALE_SDIST={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_ECDIST={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_ESDIST={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_EUDIST={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_EADIST={"ref-prefix":"OT"}
#requestHeader.Pre2Pre_Reversal={"ref-prefix":"BD"}

bss.transaction.defaultAllowedFor=NONE

bss.transaction.id=Generic
bss.transaction.allowedFor=${bss.transaction.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.transaction.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.transaction.processor.schedTime=0 0 1 * * ?
bss.transaction.processor.schedTypeDelay-sec=60
bss.transaction.processor.failOnError=false
bss.transaction.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.transaction.processor.parallelChunkNb=10
bss.transaction.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.transaction.processor.retryDelay=10
#Indicates if an automatic retry must be performed in case we receive gateway errors from nginx
bss.transaction.processor.gatewayErrorsAutomaticRetry=true
#Indicates if an immediate retry must be performed in case of connection error (or gateway errors from nginx)
bss.transaction.processor.immediateRetry=true
bss.transaction.file.uploadDescription=transaction ${bss.transaction.id} import file
bss.transaction.file.supportedFormats=CSV,JSON
bss.transaction.file.format=CSV
bss.transaction.file.csv.freemarkerTemplate=transaction_o2c_foc_import.ftl
bss.transaction.file.csv.header=senderMsisdn,receiverMsisdn,amount,productSku
bss.transaction.file.csv.hasHeader=true
bss.transaction.file.csv.defaultSeparator=,
bss.transaction.file.csv.fieldMapping.senderId=COLUMN:senderMsisdn
bss.transaction.file.csv.fieldMapping.receiverId=COLUMN:receiverMsisdn
bss.transaction.file.csv.fieldMapping.value=COLUMN:amount
bss.transaction.file.csv.fieldMapping.productSKU=COLUMN:productSku
#left side fields need to match with txe request
#-------------------------------------------------------------------------------------
# Batch Scheduling for campaign targets
#-------------------------------------------------------------------------------------

bss.campaigntargets.defaultAllowedFor=NONE

bss.campaigntargets.id=campaignTargets
bss.campaigntargets.allowedFor=${bss.campaigntargets.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.campaigntargets.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.campaigntargets.processor.schedTime=0 0 1 * * ?
bss.campaigntargets.processor.schedTypeDelay-sec=60
bss.campaigntargets.processor.failOnError=false
bss.campaigntargets.processor.chunkSize=10
bss.campaigntargets.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.campaigntargets.processor.retryDelay=10
bss.campaigntargets.file.uploadDescription=campaigntargets ${bss.campaigntargets.id} import file
bss.campaigntargets.file.supportedFormats=CSV,JSON
bss.campaigntargets.file.format=CSV
bss.campaigntargets.file.csv.freemarkerTemplate=campaign_targets.ftl
bss.campaigntargets.file.csv.header=resellerMSISDN,campaignId,kpiName,event,target
bss.campaigntargets.file.csv.hasHeader=true
bss.campaigntargets.file.csv.defaultSeparator=,
bss.campaigntargets.file.csv.fieldMapping.resellerMSISDN=COLUMN:resellerMSISDN
bss.campaigntargets.file.csv.fieldMapping.sellerId=COLUMN:Seller
bss.campaigntargets.file.csv.fieldMapping.campaignId=COLUMN:campaignId
bss.campaigntargets.file.csv.fieldMapping.kpiName=COLUMN:kpiName
bss.campaigntargets.file.csv.fieldMapping.event=COLUMN:event
bss.campaigntargets.file.csv.fieldMapping.target=COLUMN:target
